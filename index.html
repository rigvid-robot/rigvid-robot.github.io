<!DOCTYPE html>
<html>

<head>
  <meta charset="utf-8">
  <meta name="description"
    content="Robots Imitating Generated Videos for Scalable Robotic Manipulation with Zero Robot Demos">
  <meta name="keywords" content="Robotic Manipulation, Foundation Models">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Robotic Manipulation by Imitating Generated Videos with Zero Training Demos</title>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/all.min.css" />
  <script defer src="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/js/all.min.js"></script>

  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
  <style>
    /* ensure content sits below the fixed navbar */
    body {
      padding-top: 3.5rem;
    }

    /* 2) grey background, white text, inherit font */
    nav.navbar {
      background-color: #808080;
    }

    nav.navbar .navbar-item,
    nav.navbar .navbar-burger span {
      color: #fff;
      font-family: inherit;
    }

    nav.navbar .navbar-item:hover {
      background-color: rgba(255, 255, 255, 0.1);
    }

    /* 3) right-align all sections and rows */
    section,
    .rows {
      text-align: right;
    }
  </style>
</head>

<body>
  <!-- 1) Sticky Navbar -->
  <nav class="navbar is-fixed-top has-shadow" role="navigation" aria-label="main navigation">
    <div class="container">
      <div class="navbar-brand">
        <a class="navbar-item" href="#">RIGVid</a>

        <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false" data-target="mainNav">
          <span aria-hidden="true"></span>
          <span aria-hidden="true"></span>
          <span aria-hidden="true"></span>
        </a>
      </div>

      <div id="mainNav" class="navbar-menu">
        <div class="navbar-end">
          <a class="navbar-item" href="#abstract">Abstract</a>
          <a class="navbar-item" href="#explanation-video">Explanation Video</a>
          <a class="navbar-item" href="#demonstrations">Demonstrations</a>
          <a class="navbar-item" href="#insights">Insights</a>
          <a class="navbar-item" href="#results">Results</a>
          <a class="navbar-item" href="#robustness">Robustness</a>
        </div>
      </div>
    </div>
  </nav>

  <!-- Title, Authors, Affiliation, Links -->
  <section class="hero">
    <div class="hero-body">
      <div class="container is-fullhd">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">Robotic Manipulation by Imitating Generated Videos with Zero
              Training Demos</h1>
            <!-- <h2 class="subtitle is-3 conference-name">ICCV 2025</h2>               -->
            <div class="is-size-5 publication-authors">
              <span class="author-block">
                <a target="_blank" href="https://shivanshpatel35.github.io/">Shivansh Patel</a><sup>1</sup>,
              </span>
              <span class="author-block">
                <a target="_blank" href="">Shraddhaa Mohan</a><sup>1</sup>,
              </span>
              <span class="author-block">
                <a target="_blank" href="https://hanlinmai.web.illinois.edu/">Hanlin Mai</a><sup>1</sup>,
              </span>
              <span class="author-block">
                <a target="_blank" href="https://unnat.github.io">Unnat Jain</a><sup>2*</sup>,
              </span>
              <span class="author-block">
                <a target="_blank" href="https://slazebni.cs.illinois.edu/">Svetlana Lazebnik</a><sup>1*</sup>,
              </span>
              <span class="author-block">
                <a target="_blank" href="https://yunzhuli.github.io/">Yunzhu Li</a><sup>3*</sup>
              </span>
            </div>
            <div class="is-size-5 affiliation">
              <sup>1</sup>University of Illinois at Urbana-Champaign,
              <sup>2</sup>University of California, Irvine,
              <sup>3</sup>Columbia University
            </div>
            <div class="affiliation-note">
              <sup>*</sup> indicates equal advising
            </div>
            <div class="column has-text-centered">
              <div class="publication-links">
                <!-- PDF Link. -->
                <span class="link-block">
                  <a href="" class="external-link button is-normal is-rounded is-dark" target="_blank">
                    <span class="icon">
                      <svg class="svg-inline--fa fa-file-pdf" aria-hidden="true" focusable="false" data-prefix="fas"
                        data-icon="file-pdf" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"
                        data-fa-i2svg="">
                        <path fill="currentColor"
                          d="M0 64C0 28.7 28.7 0 64 0H224V128c0 17.7 14.3 32 32 32H384V304H176c-35.3 0-64 28.7-64 64V512H64c-35.3 0-64-28.7-64-64V64zm384 64H256V0L384 128zM176 352h32c30.9 0 56 25.1 56 56s-25.1 56-56 56H192v32c0 8.8-7.2 16-16 16s-16-7.2-16-16V448 368c0-8.8 7.2-16 16-16zm32 80c13.3 0 24-10.7 24-24s-10.7-24-24-24H192v48h16zm96-80h32c26.5 0 48 21.5 48 48v64c0 26.5-21.5 48-48 48H304c-8.8 0-16-7.2-16-16V368c0-8.8 7.2-16 16-16zm32 128c8.8 0 16-7.2 16-16V400c0-8.8-7.2-16-16-16H320v96h16zm80-112c0-8.8 7.2-16 16-16h48c8.8 0 16 7.2 16 16s-7.2 16-16 16H448v32h32c8.8 0 16 7.2 16 16s-7.2 16-16 16H448v48c0 8.8-7.2 16-16 16s-16-7.2-16-16V432 368z">
                        </path>
                      </svg><!-- <i class="fas fa-file-pdf"></i> Font Awesome fontawesome.com -->
                    </span>
                    <span>Paper</span>
                  </a>
                </span>
                <span class="link-block">
                  <a href="" class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="ai ai-arxiv"></i>
                    </span>
                    <span>arXiv</span>
                  </a>
                </span>
                <!-- Video Link. -->
                <span class="link-block">
                  <a href="" class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <svg class="svg-inline--fa fa-youtube" aria-hidden="true" focusable="false" data-prefix="fab"
                        data-icon="youtube" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 576 512"
                        data-fa-i2svg="">
                        <path fill="currentColor"
                          d="M549.655 124.083c-6.281-23.65-24.787-42.276-48.284-48.597C458.781 64 288 64 288 64S117.22 64 74.629 75.486c-23.497 6.322-42.003 24.947-48.284 48.597-11.412 42.867-11.412 132.305-11.412 132.305s0 89.438 11.412 132.305c6.281 23.65 24.787 41.5 48.284 47.821C117.22 448 288 448 288 448s170.78 0 213.371-11.486c23.497-6.321 42.003-24.171 48.284-47.821 11.412-42.867 11.412-132.305 11.412-132.305s0-89.438-11.412-132.305zm-317.51 213.508V175.185l142.739 81.205-142.739 81.201z">
                        </path>
                      </svg><!-- <i class="fab fa-youtube"></i> Font Awesome fontawesome.com -->
                    </span>
                    <span>Video</span>
                  </a>
                </span>
                <!-- X Link. -->
                <span class="link-block">
                  <a href="" class="external-link button is-normal is-rounded is-dark" target="_blank">
                    <span class="icon">
                      <svg class="svg-inline--fa fa-x-twitter" aria-hidden="true" focusable="false" data-prefix="fab"
                        data-icon="x-twitter" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"
                        data-fa-i2svg="">
                        <path fill="currentColor"
                          d="M389.2 48h70.6L305.6 224.2 487 464H345L233.7 318.6 106.5 464H35.8L200.7 275.5 26.8 48H172.4L272.9 180.9 389.2 48zM364.4 421.8h39.1L151.1 88h-42L364.4 421.8z">
                        </path>
                      </svg><!-- <i class="fab fa-x-twitter"></i> Font Awesome fontawesome.com -->
                    </span>
                    <span>tl;dr</span>
                  </a>
                </span>
                <!-- Code Link. -->
                <span class="link-block">
                  <a href="" class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <svg class="svg-inline--fa fa-github" aria-hidden="true" focusable="false" data-prefix="fab"
                        data-icon="github" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"
                        data-fa-i2svg="">
                        <path fill="currentColor"
                          d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z">
                        </path>
                      </svg><!-- <i class="fab fa-github"></i> Font Awesome fontawesome.com -->
                    </span>
                    <span>Code</span>
                  </a>
                </span>
              </div>

            </div>
          </div>
        </div>
      </div>
    </div>
    </div>
  </section>

  <div class="container is-max-widescreen">

    <!-- Teaser Video and Abstract -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <!-- Teaser Video -->
        <div class="row has-text-centered" style="display: flex; justify-content: center; gap: 20px;">
          <figure style="width: 80%; padding-bottom: 10px;">
            <video id="skill4" controls autoplay loop muted width="100%">
              <source src="static/videos/teaser_vid.mp4" type="video/mp4">
            </video>
          </figure>
        </div>
        <section class="section" id="abstract"></section>
        <h2 class="title is-3">Abstract</h2>

        <div class="content has-text-justified">
          <!-- Abstract Text -->
          <p>
            Can robots tackle complex tasks without ever witnessing a physical demonstration? In this work, we test the
            limits of robotic instruction following with zero robot demonstrations -- no teleoperated trajectories, no
            expert policy rollouts, and no reliance on pre-collected datasets (e.g., OpenX or Bridge). With Robots
            Imitating Generated Videos (RIGVid), <i>without a single robot trajectory</i>, we solve challenging tasks
            like pouring water and sweeping trash that previous methods addressed only through imitation learning from
            robot demos or online reinforcement learning. Our approach brings together two recent feats in computer
            vision -- physically plausible video generation and 6-DoF pose estimation -- to overcome the data
            constraints of robotic manipulation. Starting with an image observation and a free-form command (e.g.,
            ``pour water''), we leverage state-of-the-art video diffusion models to synthesize a complete demonstration
            video. We then run general-purpose object tracking on the synthetic video and retarget the resulting
            trajectory into precise, executable robot motion. The result is a scalable, data-efficient paradigm that
            outperforms deep generative baselines and paves the way for robots to autonomously acquire complex skills
            from synthetic visual representations.
          </p>
        </div>
        </section>
      </div>
    </div>

    <!-- Explanation Video -->
    <section class="section" id="explanation-video">
      <h2 class="title is-3 has-text-centered">Explanation Video</h2>
      <div class="container is-max-desktop">
        <!--/ Paper video. -->
        <div class="publication-video">
          <iframe src="https://www.youtube.com/embed/ScMzIvxBSi4?si=pm1F59o0M9IbJFtg" allow="autoplay; encrypted-media"
            allowfullscreen=""></iframe>
        </div>
      </div>
    </section>
    <section class="hero is-light is-small">
    </section>

    <!-- Method Explanation -->
    <hr class="rounded">
    <div class="rows">
      <h2 class="title is-3 has-text-centered">Robot Imitating Generated Videos (RIGVid)</h2>
      <div style="text-align: center;">
        <img src="static/images/framework.png" class="method-image" style="max-width: 80%;" />
        <!-- <img src="static/images/retargeting.png" class="method-image" style="max-width: 80%;" /> -->
      </div>
      <p class="content has-text-justified">
        Given a starting image and a free-form human command, RIGVid first generates a video based on the image,
        following the command. RIGVid then follows a three-step approach: identifying the object of interest, tracking
        objects in generated videos, and retargeting object trajectories for robot execution. By leveraging video
        diffusion models trained on large-scale web data, RIGVid generalizes to unseen tasks and environments with no
        robot-specific pre-taining or offline demonstrations.
      </p>

    </div>

     <!-- More Demos -->
     <hr class="rounded">
     <div class="rows">
       <section class="section" id="demonstrations">
         <h2 class="title is-3 has-text-centered">Demonstrations</h2>
         <!-- TODO: descriptions -->
         <p class="content has-text-justified"></p>
 
         <!-- Pour Water Video -->
         <div class="row has-text-centered" style="display: flex; justify-content: center; gap: 20px;">
           <figure style="width: 100%;">
             <video id="skill3" controls autoplay loop muted width="80%">
               <source src="static/videos/pour_water.mp4" type="video/mp4">
             </video>
           </figure>
         </div>
 
         <!-- Lift Lid Video -->
         <div class="row has-text-centered" style="display: flex; justify-content: center; gap: 20px;">
           <figure style="width: 100%;">
             <video id="skill3" controls autoplay loop muted width="80%">
               <source src="static/videos/lift_lid.mp4" type="video/mp4">
             </video>
           </figure>
         </div>
 
         <!-- Place Spatula Video -->
         <div class="row has-text-centered" style="display: flex; justify-content: center; gap: 20px;">
           <figure style="width: 100%;">
             <video id="skill3" controls autoplay loop muted width="80%">
               <source src="static/videos/place_spatula.mp4" type="video/mp4">
             </video>
           </figure>
         </div>
 
         <!-- Sweep Trash Video -->
         <div class="row has-text-centered" style="display: flex; justify-content: center; gap: 20px;">
           <figure style="width: 100%;">
             <video id="skill3" controls autoplay loop muted width="80%">
               <source src="static/videos/sweep_trash.mp4" type="video/mp4">
             </video>
           </figure>
         </div>
 
         <!-- Clean Table Video -->
         <div class="row has-text-centered" style="display: flex; justify-content: center; gap: 20px;">
           <figure style="width: 100%;">
             <video id="skill3" controls autoplay loop muted width="80%">
               <source src="static/videos/clean_table.mp4" type="video/mp4">
             </video>
           </figure>
         </div>
 
         <!-- Iron Shirt Video -->
         <div class="row has-text-centered" style="display: flex; justify-content: center; gap: 20px;">
           <figure style="width: 100%;">
             <video id="skill3" controls autoplay loop muted width="80%">
               <source src="static/videos/iron_shirt.mp4" type="video/mp4">
             </video>
           </figure>
         </div>
 
         <!-- Ketchup Upright Video -->
         <div class="row has-text-centered" style="display: flex; justify-content: center; gap: 20px;">
           <figure style="width: 100%;">
             <video id="skill3" controls autoplay loop muted width="80%">
               <source src="static/videos/ketchup_upright.mp4" type="video/mp4">
             </video>
           </figure>
         </div>
 
         <!-- Mix Pot Video -->
         <div class="row has-text-centered" style="display: flex; justify-content: center; gap: 20px;">
           <figure style="width: 100%;">
             <video id="skill3" controls autoplay loop muted width="80%">
               <source src="static/videos/mix_pot.mp4" type="video/mp4">
             </video>
           </figure>
         </div>
 
         <!-- Pour Ketchup Video -->
         <div class="row has-text-centered" style="display: flex; justify-content: center; gap: 20px;">
           <figure style="width: 100%;">
             <video id="skill3" controls autoplay loop muted width="80%">
               <source src="static/videos/pour_ketchup.mp4" type="video/mp4">
             </video>
           </figure>
         </div>
 
         <!-- Pour Kettle Video -->
         <div class="row has-text-centered" style="display: flex; justify-content: center; gap: 20px;">
           <figure style="width: 100%;">
             <video id="skill3" controls autoplay loop muted width="80%">
               <source src="static/videos/pour_kettle.mp4" type="video/mp4">
             </video>
           </figure>
         </div>
 
         <!-- Unplug Charger Video -->
         <div class="row has-text-centered" style="display: flex; justify-content: center; gap: 20px;">
           <figure style="width: 100%;">
             <video id="skill3" controls autoplay loop muted width="80%">
               <source src="static/videos/unplug_charger.mp4" type="video/mp4">
             </video>
           </figure>
         </div>
       </section>
     </div>

    <!-- Insight #1 -->
    <hr class="rounded">
    <section class="section" id="insights">
      <h2 class="title is-3 has-text-centered">Insights</h2>
      <h3 class="subtitle is-4 has-text-justified">Insight #1: Better Video Generator Leads to Higher Success Rate</h3>
      <div style="text-align: center;">
        <img src="static/images/sora_kling15_kling_16.png" class="method-image" style="max-width: 80%;" />
      </div>
      <!-- <p class="content has-text-justified" style="margin-bottom: 0px;">We observe that Kling V1.6 generate
      higher quality videos that are more aligned with the task prompt compared to SORA and Kling V1.5,
      and results in higher success rate.
      </p> -->

      <!-- Insight #2 -->
      <hr class="rounded">
      <h3 class="subtitle is-4 has-text-justified">Insight #2: Filtering Bad Videos Increases Performance</h3>
      <div style="text-align: center;">
        <img src="static/images/unfiltered_vs_filtered.png" class="method-image" style="max-width: 80%;" />
      </div>
      <!-- <p class="content has-text-justified" style="margin-bottom: 0px;"> By filtering out bad videos that are geometrically inconsistent, or 
      don't show completion of the task, we can let the robot immitate only the successful videos, leading to higher success rate.
      </p> -->

      <!-- Insight #3 -->
      <hr class="rounded">
      <h3 class="subtitle is-4 has-text-justified">Insight #3: Immitating Generated Video Matches Performance of
        Immitating Real Videos</h3>
      <div style="text-align: center;">
        <img src="static/images/real_vs_gen.png" class="method-image" style="max-width: 80%;" />
      </div>
      <!-- <p class="content has-text-justified" style="margin-bottom: 0px;">
      We show that the performance of immitating generated videos is comparable to 
      immitating real human demonstration videos. 
      </p> -->

      <!-- Insight #4 -->
      <hr class="rounded">
      <h3 class="subtitle is-4 has-text-justified">Insight #4: RIGVid Outperforms VLM-based Method</h3>
      <div style="text-align: center;">
        <img src="static/images/ours_vs_llm.png" class="method-image" style="max-width: 80%;" />
      </div>
      <!-- <p class="content has-text-justified" style="margin-bottom: 0px;">
      Our method beats the performance of ReKep, a method based on vision-language model (VLM). 
      </p> -->

  

    </section>
    <section class="section" id="results">
          <!-- Insight #5 -->
          <hr class="rounded">
          <h3 class="title is-3 has-text-centered">Results</h3>
          <h3 class="subtitle is-4 has-text-centered">RIGVid Performs Better Than Other Video-Generation for
            Robotics Methods</h3>

          <div style="text-align: center;">
            <img src="static/images/main_result.png" class="method-image" style="max-width: 100%;" />
          </div>
          <p class="content has-text-justified" style="margin-bottom: 0px;">Comparison of our method with other approaches.
            The table reports the success over 10 runs. Across different runs, the initial
            state remains the same, but the generated video can be different, leading to variations in the trajectory. For
            AVDC and Gen2Act, we replace
            their original video generation model with the stronger KlingAI v1.6 while keeping all other aspects unchanged.
            For Track2Act, we get
            the goal image from the video generated from KlingAI. The average column represents the sum of successful runs
            across all tasks.</p>
    </section>

    <!-- Robustness -->
    <hr class="rounded">
    <div class="rows">
      <section class="section" id="robustness">
        <h2 class="title is-3 has-text-centered">Robustness</h2>

        <!-- TODO: descriptions -->
        <p class="content has-text-justified">A key advantage of RIGVid is its ability to adapt to external disturbances
          during execution. Using FoundationPose, we track the object's position in real time and dynamically adjust the
          robot's end-effector trajectory. To detect deviations from the expected trajectory, we compute the object's
          pose
          relative to the precomputed motion plan. If the object strays beyond a 2 cm displacement or 20-degree
          orientation change, we classify it as a disturbance. In response, the end-effector backtracks to the last
          successfully executed trajectory point before resuming the planned motion.</p>

        <div class="rows">
          <!-- First Row  -->
          <div class="columns">
            <div class="column has-text-centered" style="display: flex; justify-content: center; gap: 20px;">
              <!-- First Video: Robust to Human Intervention -->
              <figure style="width: 100%;">
                <video id="human1" controls autoplay loop muted width="100%">
                  <source src="static/videos/robustness.mp4" type="video/mp4">
                </video>
                <figcaption>The robot detects and recovers
                  from external disturbances, backtracking to the last achieved pose
                  before resuming execution.</figcaption>
              </figure>
            </div>
            <div class="column has-text-centered" style="display: flex; justify-content: center; gap: 20px;">
              <figure style="width: 100%;">
                <video id="human1" controls autoplay loop muted width="100%">
                  <source src="static/videos/robustness2.mp4" type="video/mp4">
                </video>
                <figcaption>The robot recovers from faulty initial grasp</figcaption>
              </figure>
            </div>
          </div>

          <!-- Second Row  -->
          <div class="columns">
            <div class="column has-text-centered" style="display: flex; justify-content: center; gap: 20px;">
              <div class="row has-text-centered"
                style="display: flex; justify-content: center; gap: 20px; flex-wrap: wrap;">
                <figure style="width: 100%;">
                  <video id="human1" controls autoplay loop muted width="100%">
                    <source src="static/videos/robustness_slip.mp4" type="video/mp4">
                  </video>
                  <figcaption>The robot recovers when object slips from the grasp</figcaption>
                </figure>
              </div>
            </div>
            <div class="column has-text-centered" style="display: flex; justify-content: center; gap: 20px;">
              <div class="row has-text-centered"
                style="display: flex; justify-content: center; gap: 20px; flex-wrap: wrap;">
                <figure style="width: 100%;">
                  <video id="human1" controls autoplay loop muted width="100%">
                    <!-- TODO: Change this video to Visual Disturbance video -->
                    <source src="static/videos/robustness_slip.mp4" type="video/mp4">
                  </video>
                  <figcaption>The robot is robust against visual disturbance</figcaption>
                </figure>
              </div>
            </div>
          </div>
        </div>
      </section>
    </div>
  
  </div>

  <!-- TODO: BibTeX -->
  <!-- <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
    </div>
  </section> -->

  <!-- Footnote -->
  <footer class="footer">
    <div class="container">
      <div class="columns is-centered">
        <div class="column">
          <div class="content has-text-centered">
            <p>
              Send feedback and questions to <a href="https://shivanshpatel35.github.io/">Shivansh Patel</a>. Website
              template borrowed from <a href="https://nerfies.github.io">Nerfies</a>,
              <a href="https://rekep-robot.github.io">ReKep</a>, and <a href="https://voxposer.github.io/">VoxPoser</a>
            </p>
          </div>
        </div>
      </div>
    </div>
  </footer>


  <script>
    // Bulma navbar burger toggle
    document.addEventListener('DOMContentLoaded', () => {
      const burgers = Array.prototype.slice.call(document.querySelectorAll('.navbar-burger'), 0);
      burgers.forEach(b => b.addEventListener('click', () => {
        const menu = document.getElementById(b.dataset.target);
        b.classList.toggle('is-active');
        menu.classList.toggle('is-active');
      }));
    });
  </script>
</body>

</html>